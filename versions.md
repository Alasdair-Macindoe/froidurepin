# Introduction
Please refer to `data.md` for the input corresponding to each number.
Additionally to `runtimes.md` for the runtime of each version.  

# Running Example
For explanations consider the following semigroup over {a, b, c, d} which has [a, b] as generators and the following multiples:

```
aa = c
ab = a
ba = d
bb = a
ca = a
ac = a
cb = d
bc = d
da = b
db = a
ba = d
bd = a
```

Then let Y = the set of reduced words at a specific stage, and A = the generators for this semigroup.

Finally note that 'Concurren(t/cy) Processing Unit' is either a thread, process or task.

# Version 1 - One-Dimensional Array Data Structure with No Concurrency and Locking

In this version there is a one-dimensional array that holds the entire graph, and there are indexes stored that tell us the front and the end of the current frontier of the graph.

Using the running example we get A = [a, b]. After we initialise our data structure we get Y = [a, b] with our start = 1, and end = 2.

After we performing our multiplications to produce our Cayley table we add [c, d] this will give us Y = [a, b, c, d] with start = 3 and end = 4. This is where the calculations would end and our Y would contain a datastructure that allows us to create the graph. For example if we take Y[1] our data structure will include right[2] (this means Y[1] (a) times A[2] (b) which will give us a). In effect c and d are the forefront of our graph.

### Note

Because of how poorly I thought this out this means process queues cannot be done concurrently. This was improved upon in version 2.

## Apply Generators

The queue generated by `ApplyGenerators` is a 2-D array (technically ApplyGenerators amends in place an already created 2-D array). Each bucket is given its own array inside the main array (hence making it 2-D) and each concurrent unit of processing gets its own bucket (thus there are as many buckets as there are concurrent processing) meaning that there is no need for locking here since there cannot be any problems.

If we consider at the start our Queue Q = [[], []] which will have two units of concurrency. At the end of Apply Generators. This could become: [ [c, d], [d]]. AT this point c, d are not values but full datastructures (although no left Cayley graph created at this point).

## Merge Queue

`MergeQueues` takes all the potentially new values from `ApplyGenerators` and merges them into our reduced words collection Y if they are new, and discards them otherwise.

If we have Y = [a, b] and our Queues Q = [ [c, d], [d]] then at the end of our this method our Y = [a, b, c, d].

## Develop Left

Takes the new Y produced from MergeQueues and creates the left Cayley graph for any values that needs them. Nothing exceptionally special. No multiplications happen at this stage.

## Jobs
For this version the standard number of jobs (effectively how many fragements we take) is one per generator.

# Version 1.1.x

All of these Versions will use a bucket per generator in ApplyGenerators output and will split fragment the known search space based upon two conditions: firstly how large our frontier is and how many jobs we have (which by default is the number of generators we are given).

## Version 1.1.1 - Tasks & Locking

This version is an extension of Version 1. It has concurrency introduced using
HPC-GAP's Task system and uses locking to allow us to maintain a 1-D array for our Y set (the set of reduced words). This is done using HPC-GAP's atomic types.

# Version 2 - Paper Implementation

This implementation is almost identical to the version implemented in the paper with one exception which requires me to have one lock because of how HPC-GAP works. It is required to acquire a read-lock a fragment before adding a word to it.

## Data Structures and Supplementary Functions

### Bucket Function (Hash Function)

Unfortunately HPC-GAP does not seem to have a built in hash function for Transformations (which is what I am traditionally working with) as such I had to design my own for Transformations. Please refer to `hash-versions.md` for more information on these.

### Fragment

The paper defines a fragment. From a computational perspective a fragment is a collection of words and a value K which is used as a counter to the first unread (by Apply Generators) word. For example if Apply Generators had read the first and second word then K would be 3. Words are stored as an AtomicList structure which is just a list that has access control.  

### Word

A Word is the combination of two values. Firstly the bucket number it should be placed in (in Apply Queues) and secondly the `wordRec` which is the word's value, suffix, prefix, and all other information required.

### Word Entry

A Word Entry defines the state of a word. It defines its value, what words create it, what happens when it is multiplied (left and right) by a generator and its length.

### CreateQueues

CreateQueues method creates the buckets that each generated word (from Apply Generators) will be placed into.


## Main Algorithm

### Apply Generators

Each instance of Apply Generators created (one per task) deals with a specific fragment of reduced words (`Y` is the set of all fragments and internally `Yj` is used for the jth fragment). It uses the K value defined within that fragment to iterate until we have exceeded the size of the fragment (note that at this stage we are *never* increasing the size of fragments) and that the word is the length that we are currently iterating over.

We then require the Kth word for that fragment (internally called `YjKj`). For every generator we perform a series of instructions. Firstly we check to see if its suffix's right multiple by this generator is reduced or not and if it is not reduced then we reduce it.

Secondly we find the right multiple of this word with that generator and see if it exists. Note that no locking is required at this point since we are not ever editing anything within the set of reduced words.
If the word exists then its right multiple is updated, otherwise we create a new word with that value (which gives it a bucket number) and add it to that bucket and added to that jobs queue for Process Queues.


### Process Queues

In order to remove the requirement for locking the implementation makes each ProcessQueues loop over every word in every queue and then perform the merging steps on words that have the bucket entry corresponding to its job number. This works because each word (until the inner part) is read only and since each word can only have one bucket there can be no race conditions when we merge the word (no other task has this word). Additionally notice that the bucketing function is deterministic this means that any identical words are put in the same bucket even if they have different queue numbers. 
